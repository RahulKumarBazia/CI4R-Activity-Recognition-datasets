{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26ffb543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Library Loaded Successfully ..........\n",
      "Reading Dataset from PIckle Object\n",
      "(882, 80, 80, 1)\n"
     ]
    }
   ],
   "source": [
    "# try:\n",
    "#     import tensorflow as tf\n",
    "#     import cv2\n",
    "#     import os\n",
    "#     import pickle\n",
    "#     import numpy as np\n",
    "#     print(\"Library Loaded Successfully ..........\")\n",
    "# except:\n",
    "#     print(\"Library not Found ! \")\n",
    "\n",
    "\n",
    "# class MasterImage(object):\n",
    "\n",
    "#     def __init__(self,PATH='', IMAGE_SIZE = 50):\n",
    "#         self.PATH = PATH\n",
    "#         self.IMAGE_SIZE = IMAGE_SIZE\n",
    "\n",
    "#         self.image_data = []\n",
    "#         self.x_data = []\n",
    "#         self.y_data = []\n",
    "#         self.CATEGORIES = []\n",
    "\n",
    "#         # This will get List of categories\n",
    "#         self.list_categories = []\n",
    "\n",
    "#     def get_categories(self):\n",
    "#         for path in os.listdir(self.PATH):\n",
    "#             if '.DS_Store' in path:\n",
    "#                 pass\n",
    "#             else:\n",
    "#                 self.list_categories.append(path)\n",
    "#         print(\"Found Categories \",self.list_categories,'\\n')\n",
    "#         return self.list_categories\n",
    "\n",
    "#     def Process_Image(self):\n",
    "#         try:\n",
    "#             \"\"\"\n",
    "#             Return Numpy array of image\n",
    "#             :return: X_Data, Y_Data\n",
    "#             \"\"\"\n",
    "#             self.CATEGORIES = self.get_categories()\n",
    "#             for categories in self.CATEGORIES:                                                  # Iterate over categories\n",
    "\n",
    "#                 train_folder_path = os.path.join(self.PATH, categories)                         # Folder Path\n",
    "#                 class_index = self.CATEGORIES.index(categories)                                 # this will get index for classification\n",
    "\n",
    "#                 for img in os.listdir(train_folder_path):                                       # This will iterate in the Folder\n",
    "#                     new_path = os.path.join(train_folder_path, img)                             # image Path\n",
    "\n",
    "#                     try:        # if any image is corrupted\n",
    "#                         image_data_temp = cv2.imread(new_path,cv2.IMREAD_GRAYSCALE)                 # Read Image as numbers\n",
    "#                         image_temp_resize = cv2.resize(image_data_temp,(self.IMAGE_SIZE,self.IMAGE_SIZE))\n",
    "#                         self.image_data.append([image_temp_resize,class_index])\n",
    "#                     except:\n",
    "#                         pass\n",
    "\n",
    "#             data = np.asanyarray(self.image_data)\n",
    "\n",
    "#             # Iterate over the Data\n",
    "#             for x in data:\n",
    "#                 self.x_data.append(x[0])        # Get the X_Data\n",
    "#                 self.y_data.append(x[1])        # get the label\n",
    "\n",
    "#             X_Data = np.asarray(self.x_data) / (255.0)      # Normalize Data\n",
    "#             Y_Data = np.asarray(self.y_data)\n",
    "\n",
    "#             # reshape x_Data\n",
    "\n",
    "#             X_Data = X_Data.reshape(-1, self.IMAGE_SIZE, self.IMAGE_SIZE, 1)\n",
    "\n",
    "#             return X_Data, Y_Data\n",
    "#         except:\n",
    "#             print(\"Failed to run Function Process Image \")\n",
    "\n",
    "#     def pickle_image(self):\n",
    "\n",
    "#         \"\"\"\n",
    "#         :return: None Creates a Pickle Object of DataSet\n",
    "#         \"\"\"\n",
    "#         # Call the Function and Get the Data\n",
    "#         X_Data,Y_Data = self.Process_Image()\n",
    "\n",
    "#         # Write the Entire Data into a Pickle File\n",
    "#         pickle_out = open('X_Data','wb')\n",
    "#         pickle.dump(X_Data, pickle_out)\n",
    "#         pickle_out.close()\n",
    "\n",
    "#         # Write the Y Label Data\n",
    "#         pickle_out = open('Y_Data', 'wb')\n",
    "#         pickle.dump(Y_Data, pickle_out)\n",
    "#         pickle_out.close()\n",
    "\n",
    "#         print(\"Pickled Image Successfully \")\n",
    "#         return X_Data,Y_Data\n",
    "\n",
    "#     def load_dataset(self):\n",
    "\n",
    "#         try:\n",
    "#             # Read the Data from Pickle Object\n",
    "#             X_Temp = open('X_Data','rb')\n",
    "#             X_Data = pickle.load(X_Temp)\n",
    "\n",
    "#             Y_Temp = open('Y_Data','rb')\n",
    "#             Y_Data = pickle.load(Y_Temp)\n",
    "\n",
    "#             print('Reading Dataset from PIckle Object')\n",
    "\n",
    "#             return X_Data,Y_Data\n",
    "\n",
    "#         except:\n",
    "#             print('Could not Found Pickle File ')\n",
    "#             print('Loading File and Dataset  ..........')\n",
    "\n",
    "#             X_Data,Y_Data = self.pickle_image()\n",
    "#             return X_Data,Y_Data\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     path = r'C:\\Users\\tjfpnc\\Documents\\GitHub\\CI4R-Activity-Recognition-datasets\\train'\n",
    "#     a = MasterImage(PATH=path,\n",
    "#                     IMAGE_SIZE=80)\n",
    "\n",
    "#     X_Data,Y_Data = a.load_dataset()\n",
    "#     print(X_Data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41f6f313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 14s 885ms/step - loss: -2458.6982 - accuracy: 0.0502 - val_loss: -25133.6406 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 14s 873ms/step - loss: -61503.7070 - accuracy: 0.0535 - val_loss: -318821.6875 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 22s 1s/step - loss: -424770.8750 - accuracy: 0.0535 - val_loss: -1712371.8750 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 19s 1s/step - loss: -1781768.7500 - accuracy: 0.0535 - val_loss: -6089449.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 18s 1s/step - loss: -5467050.5000 - accuracy: 0.0535 - val_loss: -16825136.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 18s 1s/step - loss: -13749277.0000 - accuracy: 0.0535 - val_loss: -39159796.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 19s 1s/step - loss: -29980158.0000 - accuracy: 0.0535 - val_loss: -80620320.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 16s 1s/step - loss: -58443256.0000 - accuracy: 0.0535 - val_loss: -150989920.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 16s 1s/step - loss: -105265152.0000 - accuracy: 0.0535 - val_loss: -261880720.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 16s 1s/step - loss: -177156880.0000 - accuracy: 0.0535 - val_loss: -428937984.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 16s 1s/step - loss: -283627456.0000 - accuracy: 0.0535 - val_loss: -668663360.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 17s 1s/step - loss: -432797952.0000 - accuracy: 0.0535 - val_loss: -1002059072.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 15s 963ms/step - loss: -639002816.0000 - accuracy: 0.0535 - val_loss: -1448831616.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 15s 972ms/step - loss: -911007680.0000 - accuracy: 0.0535 - val_loss: -2038096128.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 17s 1s/step - loss: -1263041920.0000 - accuracy: 0.0535 - val_loss: -2796222720.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 17s 1s/step - loss: -1711922432.0000 - accuracy: 0.0535 - val_loss: -3740253696.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 17s 1s/step - loss: -2268383488.0000 - accuracy: 0.0535 - val_loss: -4916164608.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 21s 1s/step - loss: -2960107264.0000 - accuracy: 0.0535 - val_loss: -6343933952.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 20s 1s/step - loss: -3801527296.0000 - accuracy: 0.0535 - val_loss: -8064829952.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 18s 1s/step - loss: -4795878400.0000 - accuracy: 0.0535 - val_loss: -10140424192.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 18s 1s/step - loss: -5996555776.0000 - accuracy: 0.0535 - val_loss: -12563107840.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 17s 1s/step - loss: -7384866816.0000 - accuracy: 0.0535 - val_loss: -15438110720.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 21s 1s/step - loss: -9020036096.0000 - accuracy: 0.0535 - val_loss: -18756407296.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 17s 1s/step - loss: -10903555072.0000 - accuracy: 0.0535 - val_loss: -22540886016.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 19s 1s/step - loss: -13052174336.0000 - accuracy: 0.0535 - val_loss: -26874302464.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 18s 1s/step - loss: -15506609152.0000 - accuracy: 0.0535 - val_loss: -31775217664.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 17s 1s/step - loss: -18277107712.0000 - accuracy: 0.0535 - val_loss: -37317640192.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 21s 1s/step - loss: -21392513024.0000 - accuracy: 0.0535 - val_loss: -43540815872.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 19s 1s/step - loss: -24922071040.0000 - accuracy: 0.0535 - val_loss: -50496724992.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 19s 1s/step - loss: -28833798144.0000 - accuracy: 0.0535 - val_loss: -58337411072.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 20s 1s/step - loss: -33195098112.0000 - accuracy: 0.0535 - val_loss: -66966233088.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 19s 1s/step - loss: -38017630208.0000 - accuracy: 0.0535 - val_loss: -76476964864.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 19s 1s/step - loss: -43332141056.0000 - accuracy: 0.0535 - val_loss: -86964207616.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 18s 1s/step - loss: -49195110400.0000 - accuracy: 0.0535 - val_loss: -98510184448.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      " 2/16 [==>...........................] - ETA: 17s - loss: -52408332288.0000 - accuracy: 0.0500"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-a0d87da685c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_Data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_Data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from tensorflow.keras import Sequential\n",
    "# from tensorflow.keras.layers import Dense,Dropout,Activation, Flatten,Conv2D,MaxPooling2D\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Conv2D(150, (3, 3), input_shape=X_Data.shape[1:]))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Conv2D(75, (3, 3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(64))\n",
    "# model.add(Dense(1))\n",
    "# model.add(Activation('sigmoid'))\n",
    "# model.compile(loss='binary_crossentropy',\n",
    "#               optimizer='adam',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# model.fit(X_Data, Y_Data, batch_size=40, epochs=100, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d944c8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "plt.style.use('classic')\n",
    "#############################################################\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "#from keras import backend as K\n",
    "####################################################\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "image_directory = r'C:\\Users\\tjfpnc\\Documents\\GitHub\\CI4R-Activity-Recognition-datasets\\train'\n",
    "SIZE = 150\n",
    "dataset = []  #Many ways to handle data, you can use pandas. Here, we are using a list format.  \n",
    "label = []  #Place holders to define add labels. We will add 0 to all parasitized images and 1 to uninfected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "11061265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 walking1.png\n",
      "1 walking10.png\n",
      "2 walking11.png\n",
      "3 walking12.png\n",
      "4 walking13.png\n",
      "5 walking14.png\n",
      "6 walking15.png\n",
      "7 walking16.png\n",
      "8 walking17.png\n",
      "9 walking18.png\n",
      "10 walking19.png\n",
      "11 walking2.png\n",
      "12 walking20.png\n",
      "13 walking21.png\n",
      "14 walking22.png\n",
      "15 walking23.png\n",
      "16 walking24.png\n",
      "17 walking25.png\n",
      "18 walking26.png\n",
      "19 walking27.png\n",
      "20 walking28.png\n",
      "21 walking29.png\n",
      "22 walking3.png\n",
      "23 walking30.png\n",
      "24 walking31.png\n",
      "25 walking32.png\n",
      "26 walking33.png\n",
      "27 walking34.png\n",
      "28 walking35.png\n",
      "29 walking36.png\n",
      "30 walking37.png\n",
      "31 walking38.png\n",
      "32 walking39.png\n",
      "33 walking4.png\n",
      "34 walking40.png\n",
      "35 walking41.png\n",
      "36 walking42.png\n",
      "37 walking43.png\n",
      "38 walking44.png\n",
      "39 walking45.png\n",
      "40 walking46.png\n",
      "41 walking47.png\n",
      "42 walking48.png\n",
      "43 walking49.png\n",
      "44 walking5.png\n",
      "45 walking50.png\n",
      "46 walking51.png\n",
      "47 walking52.png\n",
      "48 walking53.png\n",
      "49 walking54.png\n",
      "50 walking55.png\n",
      "51 walking56.png\n",
      "52 walking57.png\n",
      "53 walking58.png\n",
      "54 walking59.png\n",
      "55 walking6.png\n",
      "56 walking60.png\n",
      "57 walking61.png\n",
      "58 walking62.png\n",
      "59 walking63.png\n",
      "60 walking64.png\n",
      "61 walking65.png\n",
      "62 walking66.png\n",
      "63 walking67.png\n",
      "64 walking68.png\n",
      "65 walking69.png\n",
      "66 walking7.png\n",
      "67 walking70.png\n",
      "68 walking71.png\n",
      "69 walking8.png\n",
      "70 walking9.png\n"
     ]
    }
   ],
   "source": [
    "walking_images = os.listdir(r'C:\\Users\\tjfpnc\\Documents\\GitHub\\CI4R-Activity-Recognition-datasets\\train\\Walking')\n",
    "for i, image_name in enumerate(walking_images):    #Remember enumerate method adds a counter and returns the enumerate object\n",
    "    print(i, image_name)\n",
    "    if (image_name.split('.')[1] == 'png'):\n",
    "        image = cv2.imread(r'C:\\Users\\tjfpnc\\Documents\\GitHub\\CI4R-Activity-Recognition-datasets\\train\\Walking' + image_name)\n",
    "        image = np.asarray(image)\n",
    "        image = image.resize((SIZE, SIZE))\n",
    "        dataset.append(np.array(image))\n",
    "        label.append(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4620c254",
   "metadata": {},
   "outputs": [],
   "source": [
    "WheeledChair_images = os.listdir(r'C:\\Users\\tjfpnc\\Documents\\GitHub\\CI4R-Activity-Recognition-datasets\\train\\WheeledChair')\n",
    "for i, image_name in enumerate(WheeledChair_images):\n",
    "    if (image_name.split('.')[1] == 'png'):\n",
    "        image = cv2.imread(r'C:\\Users\\tjfpnc\\Documents\\GitHub\\CI4R-Activity-Recognition-datasets\\train\\WheeledChair' + image_name)\n",
    "        image = np.asarray(image)\n",
    "        image = image.resize((SIZE, SIZE))\n",
    "        dataset.append(np.array(image))\n",
    "        label.append(0)\n",
    "\n",
    "dataset = np.array(dataset)\n",
    "label = np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9db02412",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [368, 365]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-aea0dd9bbf0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#from keras.utils import to_categorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.40\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#Without scaling (normalize) the training may not converge.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2170\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"At least one array required as input\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2172\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2174\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    297\u001b[0m     \"\"\"\n\u001b[0;32m    298\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[0;32m    263\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [368, 365]"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#from keras.utils import to_categorical\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset, label, test_size = 0.40, random_state = 0)\n",
    "\n",
    "#Without scaling (normalize) the training may not converge. \n",
    "#Normalization is a rescaling of the data from the original range \n",
    "#so that all values are within the range of 0 and 1.\n",
    "from keras.utils import normalize\n",
    "X_train = normalize(X_train, axis=1)\n",
    "X_test = normalize(X_test, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb23e6e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
